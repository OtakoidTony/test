{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영화 감상 리뷰 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **이름: 원알렉스**\n",
    "- **학번: 20185143**\n",
    "- **학과: 빅데이터**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('../data/IMDB_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 처음 5개의 데이터 확인\n",
    "> - 여기서도 볼수 있듯이 데이터 중간에 불필요한 텍스트들이 존재\n",
    "> - 결과값도 또한 이산값이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - review와 sentiment 두개의 칼럼으로 이루어진 데이터\n",
    "> - 총 50000개의 샘플 데이터를 가지고 null값은 없으므로 제거해줄 필요가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - sentiment의 값을 확인해보면 균등하게 나뉘어져 있으므로\n",
    "> - 데이터 불균형으로 인한 모델의 일반화 성능 왜곡이 발생하진 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. 샘플 하나를 가지고 NLP를 어떻게 진행하는 것인지에 대한 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 샘플 데이터를 확인해보면 중간에 불필요한 텍스트들이 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = reviews['review'].loc[1]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NLP 전처리 과정\n",
    "> - HTML 태그 제거\n",
    "> - 특수기호와 문장기호 제거\n",
    "> - 불용어 제거\n",
    "> - Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. HTML 태그 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(review, \"html.parser\")\n",
    "review = soup.get_text()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Regular Expressions 라이브러리를 통해 단어들을 제외한 모든 문장기호와 특수기호들을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production  The filming technique is very unassuming  very old time BBC fashion and gives a comforting  and sometimes discomforting  sense of realism to the entire piece  The actors are extremely well chosen  Michael Sheen not only  has got all the polari  but he has all the voices down pat too  You can truly see the seamless editing guided by the references to Williams  diary entries  not only is it well worth the watching but it is a terrificly written and performed piece  A masterful production about one of the great master s of comedy and his life  The realism really comes home with the little things  the fantasy of the guard which  rather than use the traditional  dream  techniques remains solid then disappears  It plays on our knowledge and our senses  particularly with the scenes concerning Orton and Halliwell and the sets  particularly of their flat with Halliwell s murals decorating every surface  are terribly well done '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. 텍스트들을 모두 균일하게 소문자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production  the filming technique is very unassuming  very old time bbc fashion and gives a comforting  and sometimes discomforting  sense of realism to the entire piece  the actors are extremely well chosen  michael sheen not only  has got all the polari  but he has all the voices down pat too  you can truly see the seamless editing guided by the references to williams  diary entries  not only is it well worth the watching but it is a terrificly written and performed piece  a masterful production about one of the great master s of comedy and his life  the realism really comes home with the little things  the fantasy of the guard which  rather than use the traditional  dream  techniques remains solid then disappears  it plays on our knowledge and our senses  particularly with the scenes concerning orton and halliwell and the sets  particularly of their flat with halliwell s murals decorating every surface  are terribly well done '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4. 불용어 제거를 하기 위해서, 모든 단어들을 검사해야되므로 개별적인 항목으로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'the',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'is',\n",
       " 'very',\n",
       " 'unassuming',\n",
       " 'very',\n",
       " 'old',\n",
       " 'time',\n",
       " 'bbc',\n",
       " 'fashion',\n",
       " 'and',\n",
       " 'gives',\n",
       " 'a',\n",
       " 'comforting',\n",
       " 'and',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'realism',\n",
       " 'to',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'the',\n",
       " 'actors',\n",
       " 'are',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'not',\n",
       " 'only',\n",
       " 'has',\n",
       " 'got',\n",
       " 'all',\n",
       " 'the',\n",
       " 'polari',\n",
       " 'but',\n",
       " 'he',\n",
       " 'has',\n",
       " 'all',\n",
       " 'the',\n",
       " 'voices',\n",
       " 'down',\n",
       " 'pat',\n",
       " 'too',\n",
       " 'you',\n",
       " 'can',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'the',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'references',\n",
       " 'to',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'not',\n",
       " 'only',\n",
       " 'is',\n",
       " 'it',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'the',\n",
       " 'watching',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'and',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'a',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'about',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'great',\n",
       " 'master',\n",
       " 's',\n",
       " 'of',\n",
       " 'comedy',\n",
       " 'and',\n",
       " 'his',\n",
       " 'life',\n",
       " 'the',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'with',\n",
       " 'the',\n",
       " 'little',\n",
       " 'things',\n",
       " 'the',\n",
       " 'fantasy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guard',\n",
       " 'which',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'use',\n",
       " 'the',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'then',\n",
       " 'disappears',\n",
       " 'it',\n",
       " 'plays',\n",
       " 'on',\n",
       " 'our',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'our',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'with',\n",
       " 'the',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'and',\n",
       " 'halliwell',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'of',\n",
       " 'their',\n",
       " 'flat',\n",
       " 'with',\n",
       " 'halliwell',\n",
       " 's',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'are',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5. 불용어 제거 - stopwords 세트에 있는 단어들은 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'old',\n",
       " 'time',\n",
       " 'bbc',\n",
       " 'fashion',\n",
       " 'gives',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actors',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voices',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'references',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entries',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'comes',\n",
       " 'home',\n",
       " 'little',\n",
       " 'things',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'techniques',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'plays',\n",
       " 'knowledge',\n",
       " 'senses',\n",
       " 'particularly',\n",
       " 'scenes',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'sets',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwell',\n",
       " 'murals',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6. Stemming/Lemmatization - 단어의 원형 상태로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Stemming은 단어 자체만을 판단 후 변환\n",
    "> - Lemmatization은 단어가 포함된 문장에서의 품사까지 판단하여 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonder',\n",
       " 'littl',\n",
       " 'product',\n",
       " 'film',\n",
       " 'techniqu',\n",
       " 'unassum',\n",
       " 'old',\n",
       " 'time',\n",
       " 'bbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'sometim',\n",
       " 'discomfort',\n",
       " 'sens',\n",
       " 'realism',\n",
       " 'entir',\n",
       " 'piec',\n",
       " 'actor',\n",
       " 'extrem',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voic',\n",
       " 'pat',\n",
       " 'truli',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'edit',\n",
       " 'guid',\n",
       " 'refer',\n",
       " 'william',\n",
       " 'diari',\n",
       " 'entri',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watch',\n",
       " 'terrificli',\n",
       " 'written',\n",
       " 'perform',\n",
       " 'piec',\n",
       " 'master',\n",
       " 'product',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedi',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'realli',\n",
       " 'come',\n",
       " 'home',\n",
       " 'littl',\n",
       " 'thing',\n",
       " 'fantasi',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'tradit',\n",
       " 'dream',\n",
       " 'techniqu',\n",
       " 'remain',\n",
       " 'solid',\n",
       " 'disappear',\n",
       " 'play',\n",
       " 'knowledg',\n",
       " 'sens',\n",
       " 'particularli',\n",
       " 'scene',\n",
       " 'concern',\n",
       " 'orton',\n",
       " 'halliwel',\n",
       " 'set',\n",
       " 'particularli',\n",
       " 'flat',\n",
       " 'halliwel',\n",
       " 'mural',\n",
       " 'decor',\n",
       " 'everi',\n",
       " 'surfac',\n",
       " 'terribl',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 보시면 품사를 판단하지 않아서 정확한 원형 형태가 되지 않음\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "review_s = [ps.stem(word) for word in review]\n",
    "review_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful',\n",
       " 'little',\n",
       " 'production',\n",
       " 'filming',\n",
       " 'technique',\n",
       " 'unassuming',\n",
       " 'old',\n",
       " 'time',\n",
       " 'bbc',\n",
       " 'fashion',\n",
       " 'give',\n",
       " 'comforting',\n",
       " 'sometimes',\n",
       " 'discomforting',\n",
       " 'sense',\n",
       " 'realism',\n",
       " 'entire',\n",
       " 'piece',\n",
       " 'actor',\n",
       " 'extremely',\n",
       " 'well',\n",
       " 'chosen',\n",
       " 'michael',\n",
       " 'sheen',\n",
       " 'got',\n",
       " 'polari',\n",
       " 'voice',\n",
       " 'pat',\n",
       " 'truly',\n",
       " 'see',\n",
       " 'seamless',\n",
       " 'editing',\n",
       " 'guided',\n",
       " 'reference',\n",
       " 'williams',\n",
       " 'diary',\n",
       " 'entry',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'terrificly',\n",
       " 'written',\n",
       " 'performed',\n",
       " 'piece',\n",
       " 'masterful',\n",
       " 'production',\n",
       " 'one',\n",
       " 'great',\n",
       " 'master',\n",
       " 'comedy',\n",
       " 'life',\n",
       " 'realism',\n",
       " 'really',\n",
       " 'come',\n",
       " 'home',\n",
       " 'little',\n",
       " 'thing',\n",
       " 'fantasy',\n",
       " 'guard',\n",
       " 'rather',\n",
       " 'use',\n",
       " 'traditional',\n",
       " 'dream',\n",
       " 'technique',\n",
       " 'remains',\n",
       " 'solid',\n",
       " 'disappears',\n",
       " 'play',\n",
       " 'knowledge',\n",
       " 'sens',\n",
       " 'particularly',\n",
       " 'scene',\n",
       " 'concerning',\n",
       " 'orton',\n",
       " 'halliwell',\n",
       " 'set',\n",
       " 'particularly',\n",
       " 'flat',\n",
       " 'halliwell',\n",
       " 'mural',\n",
       " 'decorating',\n",
       " 'every',\n",
       " 'surface',\n",
       " 'terribly',\n",
       " 'well',\n",
       " 'done']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming 보다 정확한 결과를 보여줌\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "review = [lem.lemmatize(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7. 다시 한 덩어리로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production filming technique unassuming old time bbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwell mural decorating every surface terribly well done'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 보시면 분석에 영향을 미칠 필요한 단어들만으로 이루어짐\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 8. 이 단어들을 벡터화 시켜야하므로, 먼저 말뭉치(corpus)에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []  # 말뭉치 생성\n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 벡터화를 위해서 다음과 같은 모델들을 적용\n",
    "\n",
    "> - CountVectorizer (Bag of Words Model)\n",
    "> - TfidfVectorizer (Bag of Words Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,\n",
       "        1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()  # 모델 생성\n",
    "review_count_vec = count_vec.fit_transform(corpus)  # 말뭉치를 가지고 벡터화\n",
    "\n",
    "review_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.19425717,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.19425717, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.29138576, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()  # 모델 생성\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)  # 말뭉치를 가지고 벡터화\n",
    "\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 10. 결과값(y)들을 이산적인 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['sentiment'] = reviews['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3. 위와 같은 과정으로 전체 데이터에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    soup = BeautifulSoup(reviews['review'][i], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. CountVectorizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer Model\n",
    "# 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW 인코딩한 벡터를 만든다.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=50000, min_df=5, stop_words='english')\n",
    "X_cv = cv.fit_transform(corpus)  # 벡터화\n",
    "y_cv = reviews.iloc[0:50000, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋과 테스트셋 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cv_train, X_cv_test, y_cv_train, y_cv_test = train_test_split(X_cv, y_cv, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.99\n",
      "테스트 세트 정확도: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression - CountVectorizer\n",
    "# 과대적합 발생\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state = 0)\n",
    "lr.fit(X_cv_train, y_cv_train)\n",
    "print('훈련 세트 정확도: {:.2f}'.format(lr.score(X_cv_train, y_cv_train)))\n",
    "print('테스트 세트 정확도: {:.2f}'.format(lr.score(X_cv_test, y_cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 평균 점수: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 교차검증 - CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_cv_train, y_cv_train, cv=5)\n",
    "print('교차 검증 평균 점수: {:.2f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수: 0.88\n",
      "최적의 매개변수:  {'C': 0.1}\n",
      "최적의 매개변수를 사용한 훈련 점수: 0.96\n",
      "최적의 매개변수를 사용한 테스트 점수: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV - CountVectorizer\n",
    "# 과대적합 조금 완화됨\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_cv_train, y_cv_train)\n",
    "print('최상의 교차 검증 점수: {:.2f}'.format(grid.best_score_))\n",
    "print('최적의 매개변수: ', grid.best_params_)\n",
    "print('최적의 매개변수를 사용한 훈련 점수: {:.2f}'.format(grid.score(X_cv_train, y_cv_train)))\n",
    "print('최적의 매개변수를 사용한 테스트 점수: {:.2f}'.format(grid.score(X_cv_test, y_cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "C:\\Users\\lg\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4445  590]\n",
      " [ 532 4433]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_cv_pred = grid.predict(X_cv_test)\n",
    "confusion = confusion_matrix(y_cv_test, y_cv_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.88      0.89      5035\n",
      "     Postive       0.88      0.89      0.89      4965\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_cv_test, y_cv_pred, target_names=['Negative', 'Postive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
